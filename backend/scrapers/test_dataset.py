# test_dataset.py
import json
import os
import pytest

BASE = "dataset"

# Skip whole module when dataset folder is not available (conservative)
if not os.path.isdir(BASE):
    pytest.skip("dataset folder not present - skipping dataset integration checks", allow_module_level=True)

def load_json(path):
    with open(f"{BASE}/{path}", 'r', encoding='utf-8') as f:
        return json.load(f)

def load_text(path):
    with open(f"{BASE}/{path}", 'r', encoding='utf-8') as f:
        return f.read().strip().split('\n')

print("="*50)
print("ğŸ§ª TEST DU DATASET")
print("="*50)

# 1. Dictionnaire
print("\nğŸ“– DICTIONNAIRE")
dico = load_json("lexiques/dictionnaire_mg.json")
print(f"   {len(dico)} mots")
print(f"   Exemples: {dico[:10]}")

# 2. Test orthographe
print("\nâœï¸  TEST ORTHOGRAPHE")
test_words = ["tsara", "malagasy", "xyz", "bonjour", "fitiavana", "teny"]
for word in test_words:
    status = "âœ“" if word.lower() in [w.lower() for w in dico] else "âœ—"
    print(f"   {status} '{word}'")

# 3. N-grams (autocomplÃ©tion)
print("\nğŸ”® AUTOCOMPLÃ‰TION (bigrams)")
ngrams = load_json("stats/ngrams.json")
bigrams = ngrams["bigrams"]
print(f"   {len(bigrams)} bigrams")

# Test: mots aprÃ¨s "ny"
ny_suggestions = [k.split()[1] for k in bigrams.keys() if k.startswith("ny ")][:5]
print(f"   'ny' â†’ {ny_suggestions}")

# Test: mots aprÃ¨s "dia"
dia_suggestions = [k.split()[1] for k in bigrams.keys() if k.startswith("dia ")][:5]
print(f"   'dia' â†’ {dia_suggestions}")

# 4. Sentiment
print("\nğŸ˜Š ANALYSE SENTIMENT")
sentiment = load_json("lexiques/sentiment.json")
print(f"   Positifs: {sentiment['positive'][:5]}...")
print(f"   NÃ©gatifs: {sentiment['negative'][:5]}...")

# Test phrase
test_phrase = "tsara sy mahafinaritra"
words = test_phrase.split()
pos = sum(1 for w in words if w in sentiment['positive'])
neg = sum(1 for w in words if w in sentiment['negative'])
result = "POSITIF ğŸ˜Š" if pos > neg else "NÃ‰GATIF ğŸ˜" if neg > pos else "NEUTRE ğŸ˜"
print(f"   Test: '{test_phrase}' â†’ {result}")

# 5. NER
print("\nğŸ“ RECONNAISSANCE ENTITÃ‰S")
ner = load_json("lexiques/ner_gazetteer.json")
print(f"   Villes: {ner['cities'][:5]}...")
print(f"   RÃ©gions: {ner['regions'][:5]}...")

# Test
test_text = "Antananarivo dia renivohitra"
found = [w for w in test_text.split() if w in ner['cities']]
print(f"   Test: '{test_text}' â†’ Villes trouvÃ©es: {found}")

# 6. Phonotactique
print("\nğŸ”¤ RÃˆGLES ORTHOGRAPHE")
phono = load_json("rules/phonotactics.json")
print(f"   Patterns invalides: {phono['invalid_combinations'][:5]}...")

# Test
invalid_words = ["nbola", "mkasa", "tsara", "teny"]
for w in invalid_words:
    has_invalid = any(p in w for p in phono['invalid_combinations'])
    status = "âœ— invalide" if has_invalid else "âœ“ valide"
    print(f"   '{w}' â†’ {status}")

# 7. Stats
print("\nğŸ“Š STATISTIQUES CORPUS")
freq = load_json("stats/word_frequencies.json")
top_words = list(freq.items())[:10]
print(f"   Top 10 mots:")
for word, count in top_words:
    print(f"      {word:<15} {count}")

print("\n" + "="*50)
print("âœ… DATASET FONCTIONNEL!")
print("="*50)